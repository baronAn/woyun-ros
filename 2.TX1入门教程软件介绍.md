#  TX1安装CUDA
    说明：

    介绍如何在TX1安装CUDA7
    步骤：

    下载cuda-repo-l4t-r23.1-7-0-local7.0-73armhf.deb，执行：
    
    sudo dpkg -i cuda-repo-l4t-r23.1-7-0-local_7.0-73_armhf.deb  
    
    安装cuda仓库，然后执行:
    
    sudo apt-get update  
    sudo apt-get install cuda-toolkit-7-0  
    
    更新系统并进行安装，安装完后，执行:
    
    cat << END >> ~/.bashrc  
    # Add 32-bit CUDA library & binary paths:
    export PATH=/usr/local/cuda-7.0/bin:\$PATH  
    export LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib:\$LD_LIBRARY_PATH  
    END  
    更新环境并执行:
    
    source  ~/.bashrc 
    
    检查是否成功:
    
    ubuntu@tegra-ubuntu:~$ nvcc --version  
    nvcc: NVIDIA (R) Cuda compiler driver  
    Copyright (c) 2005-2015 NVIDIA Corporation  
    Built on Sun_Nov_15_11:52:02_CST_2015  
    Cuda compilation tools, release 7.0, V7.0.72  
    
# TX1安装OPENCV
    说明：

    介绍如何在TX1上安装OpenCV
    L4T 28.1
    OpenCV 3.3
    步骤：

    安装脚本下载
    脚本内容如下：
    
    #!/bin/bash
    # License: MIT. See license file in root directory
    # Copyright(c) JetsonHacks (2017)
    cd $HOME
    sudo apt-get install -y \
    libglew-dev \
    libtiff5-dev \
    zlib1g-dev \
    libjpeg-dev \
    libpng12-dev \
    libjasper-dev \
    libavcodec-dev \
    libavformat-dev \
    libavutil-dev \
    libpostproc-dev \
    libswscale-dev \
    libeigen3-dev \
    libtbb-dev \
    libgtk2.0-dev \
    cmake \
    pkg-config

    # Python 2.7
    sudo apt-get install -y python-dev python-numpy python-py python-pytest
    # GStreamer support
    sudo apt-get install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev 


    git clone https://github.com/opencv/opencv.git
    cd opencv
    git checkout -b v3.3.0 3.3.0
    # This is for the test data
    cd $HOME
    git clone https://github.com/opencv/opencv_extra.git
    cd opencv_extra
    git checkout -b v3.3.0 3.3.0

    cd $HOME/opencv
    mkdir build
    cd build
    # Jetson TX1 
    cmake \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_INSTALL_PREFIX=/usr \
    -DBUILD_PNG=OFF \
    -DBUILD_TIFF=OFF \
    -DBUILD_TBB=OFF \
    -DBUILD_JPEG=OFF \
    -DBUILD_JASPER=OFF \
    -DBUILD_ZLIB=OFF \
    -DBUILD_EXAMPLES=ON \
    -DBUILD_opencv_java=OFF \
    -DBUILD_opencv_python2=ON \
    -DBUILD_opencv_python3=OFF \
    -DENABLE_PRECOMPILED_HEADERS=OFF \
    -DWITH_OPENCL=OFF \
    -DWITH_OPENMP=OFF \
    -DWITH_FFMPEG=ON \
    -DWITH_GSTREAMER=ON \
    -DWITH_GSTREAMER_0_10=OFF \
    -DWITH_CUDA=ON \
    -DWITH_GTK=ON \
    -DWITH_VTK=OFF \
    -DWITH_TBB=ON \
    -DWITH_1394=OFF \
    -DWITH_OPENEXR=OFF \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0 \
    -DCUDA_ARCH_BIN=5.3 \
    -DCUDA_ARCH_PTX="" \
    -DINSTALL_C_EXAMPLES=ON \
    -DINSTALL_TESTS=ON \
    -DOPENCV_TEST_DATA_PATH=../opencv_extra/testdata \
    ../

    # Consider running jetson_clocks.sh before compiling
    make -j4
    
    安装：
    
    $ git clone https://github.com/jetsonhacks/buildOpenCVTX1.git
    $ cd buildOpenCVTX1
    $ ./buildOpenCV.sh
    $ cd ~/opencv/build
    $ make
    $ sudo make install  
    
# TX1安装pyTorch
    说明：

    介绍如何在TX1和TX2下安装pyTorch
    步骤：

    创建脚本：
    
    mkdir pytorch
    cd pytorch
    vim pytorch_jetson_install.sh
    
    脚本内容：
    #!/bin/bash
    #
    # pyTorch install script for NVIDIA Jetson TX1/TX2,
    # from a fresh flashing of JetPack 2.3.1 / JetPack 3.0
    #
    # note:  pyTorch documentation calls for use of Anaconda,
    #        however Anaconda isn't available for aarch64.
    #        Instead, we install directly from source using setup.py
    sudo apt-get install python-pip

    # upgrade pip
    pip install -U pip
    pip --version
    # pip 9.0.1 from /home/ubuntu/.local/lib/python2.7/site-packages (python 2.7)

    # clone pyTorch repo
    git clone http://github.com/pytorch/pytorch
    cd pytorch

    # install prereqs
    sudo pip install -U setuptools
    sudo pip install -r requirements.txt

    # Develop Mode:
    python setup.py build_deps
    sudo python setup.py develop

    # Install Mode:  (substitute for Develop Mode commands)
    #sudo python setup.py install

    # Verify CUDA (from python interactive terminal)
    # import torch
    # print(torch.cuda.is_available())
    # a = torch.cuda.FloatTensor(2)
    # print(a)
    # b = torch.randn(2).cuda()
    # print(b)
    # c = a + b
    # print(c)
    分配执行权限，执行脚本：
    chmod +x pytorch_jetson_install.sh
    sudo ./pytorch_jetson_install.sh

# TX1安装TensorFlow(0.11)
    说明：

    介绍如何在TX1上安装TensorFlow
    准备：

    利用Jetpack安装如下：

    L4T 24.2.1 an Ubuntu 16.04 64-bit variant (aarch64)
    CUDA 8.0
    cuDNN 5.1.5
    TensorFlow安装需要用到CUDA和cuDNN

    TensorFlow占用比较多空间，TX1通常空间不足，最好增加64G+的U盘作为root分区启动，增加交换分区大小为8G+

    安装：

    下载脚本：
    mkdir ~/dl
    cd ~/dl
    git clone https://github.com/jetsonhacks/installTensorFlowTX1.git
    cd installTensorFlowTX1
    使用/usr/local/lib库
    $ ./setLocalLib.sh
    安装依赖：
    chmod +x installPrerequisites.sh
    ./installPrerequisites.sh
    包含安装java，Protobuf，grpc-java ，Bazel等
    下载tensorflow代码
    $ ./cloneTensorFlow.sh  
    设置环境变量
    $ ./setTensorFlowEV.sh
    编译TensorFlow
    $ ./buildTensorFlow.sh
    打包成whl文件，放在$HOME目录下,如：tensorflow-0.11.0-py2-none-any.whl
    $ ./packageTensorFlow.sh
    安装whl文件
    $ pip install $HOME/tensorflow-0.11.0-py2-none-any.whl
    测试：

    运行TensorFlow例子：
    $ cd $HOME/tensorflow
    $ time python tensorflow/models/image/mnist/convolutional.py
    
# TX1安装Caffe
    说明：

    介绍如何在TX1上安装caffe
    步骤：

    建立dl目录，下载安装脚本：
    
    mkdir dl
    cd dl
    git clone https://github.com/jetsonhacks/installCaffeJTX1.git
    cd installCaffeJTX1
    
    设置CPU and GPU clocks为最大：
    
    $ sudo ./jetson_clocks.sh
    
    jetson_clocks.sh脚本内容为：
    
    #!/bin/bash
    # Copyright (c) 2015-2016, NVIDIA CORPORATION. All rights reserved.
    #
    # Redistribution and use in source and binary forms, with or without
    # modification, are permitted provided that the following conditions
    # are met:
    #  * Redistributions of source code must retain the above copyright
    #    notice, this list of conditions and the following disclaimer.
    #  * Redistributions in binary form must reproduce the above copyright
    #    notice, this list of conditions and the following disclaimer in the
    #    documentation and/or other materials provided with the distribution.
    #  * Neither the name of NVIDIA CORPORATION nor the names of its
    #    contributors may be used to endorse or promote products derived
    #    from this software without specific prior written permission.
    #
    # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
    # EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
    # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
    # PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
    # CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
    # EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
    # PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
    # PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
    # OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
    # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
    # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

    CONF_FILE=${HOME}/l4t_dfs.conf
    RED='\e[0;31m'
    GREEN='\e[0;32m'
    BLUE='\e[0;34m'
    BRED='\e[1;31m'
    BGREEN='\e[1;32m'
    BBLUE='\e[1;34m'
    NC='\e[0m' # No Color

    usage()
    {
        if [ "$1" != "" ]; then
            echo -e ${RED}"$1"${NC}
        fi

        echo "usage:"

        cat >& 2 <<EOF
        jetson_max_l4t.sh [options]
        options,
        --show                display current settings
        --store [file]        store current settings to a file (default: /home/ubuntu/l4t_dfs.conf)
        --restore [file]      restore saved settings from a file (default: /home/ubuntu/l4t_dfs.conf)
    EOF

    exit 0
    }

    restore()
    {
    for conf in `cat $CONF_FILE`; do
        file=`echo $conf | cut -f1 -d :`
        data=`echo $conf | cut -f2 -d :`
        case $file in
            /sys/devices/system/cpu/cpu*/online |\
            /sys/kernel/debug/clock/override*/state )
                if [ `cat $file` -ne $data ]; then
                    echo $data > $file
                fi
                ;;
            *)
                echo $data > $file
                ret=$?
                if [ ${ret} -ne 0 ]; then
                    echo "Error: Failed to restore $file"
                fi
                ;;
        esac
    done
    }

    store()
    {
        for file in $@; do
             if [ -e "${file}" ]; then
                echo "$file:`cat $file`" >> $CONF_FILE
             fi
        done
    }

    do_fan()
    {
      # Jetson-TK1 CPU fan is always ON.
        if [ -e /sys/devices/soc0/machine ]; then
            machine=`cat /sys/devices/soc0/machine`
              if [ "${machine}" = "jetson-tk1" ] ; then
              return
              fi
         fi

    if [ ! -w /sys/kernel/debug/tegra_fan/target_pwm ]; then
        echo "Can't access Fan!"
        return
    fi

    case $ACTION in
        show)
            echo "Fan: speed=`cat /sys/kernel/debug/tegra_fan/target_pwm`"
            ;;
        store)
            store /sys/kernel/debug/tegra_fan/target_pwm
            ;;
        *)
            FAN_SPEED=255
            echo $FAN_SPEED > /sys/kernel/debug/tegra_fan/target_pwm
            ;;
    esac
    }

    do_clusterswitch()
    {
    case $ACTION in
        show)
            if [ -d /sys/kernel/cluster ]; then
                ACTIVE_CLUSTER=`cat /sys/kernel/cluster/active`
                echo "CPU Cluster Switching: Active Cluster ${ACTIVE_CLUSTER}"
            else
                echo "CPU Cluster Switching: Disabled"
            fi
            ;;
        store)
            if [ -d /sys/kernel/cluster ]; then
                store "/sys/kernel/cluster/immediate"
                store "/sys/kernel/cluster/force"
                store "/sys/kernel/cluster/active"
            fi
            ;;
        *)
            if [ -d /sys/kernel/cluster ]; then
                echo 1 > /sys/kernel/cluster/immediate
                echo 0 > /sys/kernel/cluster/force
                echo G > /sys/kernel/cluster/active
            fi
            ;;
    esac
    }

    do_hotplug()
    {
    CPU_HOTPLUG_STAT=`cat /sys/devices/system/cpu/cpuquiet/tegra_cpuquiet/enable`

    case $ACTION in
        show)
            echo "CPU HOTPLUG: $CPU_HOTPLUG_STAT"
            echo "Online CPUs: `cat /sys/devices/system/cpu/online`"
            for folder in /sys/devices/system/cpu/cpu[0-9]; do
                if [ -e "${folder}/cpufreq/scaling_cur_freq" ]; then
                    CPU=`echo ${folder} | cut -c 25-`
                    echo "$CPU: `cat ${folder}/cpufreq/scaling_cur_freq`"
                fi
            done
            ;;
        store)
            store "/sys/devices/system/cpu/cpuquiet/tegra_cpuquiet/enable"
            for file in /sys/devices/system/cpu/cpu*/online; do
                store $file
            done
            ;;
        *)
            echo 0 > /sys/devices/system/cpu/cpuquiet/tegra_cpuquiet/enable
            for file in /sys/devices/system/cpu/cpu*/online; do
                if [ `cat $file` -eq 0 ]; then
                    echo 1 > $file
                fi
            done
    esac
    }

    do_cpu()
    {
    FRQ_GOVERNOR=`cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor`
    CPU_MIN_FREQ=`cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_min_freq`
    CPU_MAX_FREQ=`cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq`
    CPU_CUR_FREQ=`cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq`

    case $ACTION in
        show)
            echo "CPU frequency Governor: $FRQ_GOVERNOR"
            echo "CPU MinFreq=$CPU_MIN_FREQ MaxFreq=$CPU_MAX_FREQ CurrentFreq=$CPU_CUR_FREQ"
            ;;
        store)
            store "/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor"

            if [ -d /sys/devices/system/cpu/cpufreq/$FRQ_GOVERNOR ]; then
                store `find /sys/devices/system/cpu/cpufreq/$FRQ_GOVERNOR -type f -perm -g+r`
            fi
            ;;
        *)
            echo userspace > /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
            echo $CPU_MAX_FREQ >  /sys/devices/system/cpu/cpu0/cpufreq/scaling_setspeed
            ;;
    esac
    }

    do_gpu()
    {
    GPU_MIN_FREQ=`cat /sys/kernel/debug/clock/override.gbus/min`
    GPU_MAX_FREQ=`cat /sys/kernel/debug/clock/override.gbus/max`
    GPU_CUR_FREQ=`cat /sys/kernel/debug/clock/override.gbus/rate`
    GPU_FREQ_OVERRIDE=`cat /sys/kernel/debug/clock/override.gbus/state`

    case $ACTION in
        show)
            echo "GPU MinFreq=$GPU_MIN_FREQ MaxFreq=$GPU_MAX_FREQ CurrentFreq=$GPU_CUR_FREQ FreqOverride=$GPU_FREQ_OVERRIDE"
            ;;
        store)
            store /sys/kernel/debug/clock/override.gbus/rate
            store /sys/kernel/debug/clock/override.gbus/state
            ;;
        *)
            echo $GPU_MAX_FREQ > /sys/kernel/debug/clock/override.gbus/rate
            echo 1 > /sys/kernel/debug/clock/override.gbus/state
            ret=$?
            if [ ${ret} -ne 0 ]; then
                echo "Error: Failed to max GPU frequency!"
            fi
            ;;
    esac
    }

    do_emc()
    {
    EMC_MIN_FREQ=`cat /sys/kernel/debug/clock/override.emc/min`
    EMC_MAX_FREQ=`cat /sys/kernel/debug/clock/override.emc/max`
    EMC_CUR_FREQ=`cat /sys/kernel/debug/clock/override.emc/rate`
    EMC_FREQ_OVERRIDE=`cat /sys/kernel/debug/clock/override.emc/state`

    case $ACTION in
        show)
            echo "EMC MinFreq=$EMC_MIN_FREQ MaxFreq=$EMC_MAX_FREQ CurrentFreq=$EMC_CUR_FREQ FreqOverride=$EMC_FREQ_OVERRIDE"
            ;;
        store)
            store /sys/kernel/debug/clock/override.emc/rate
            store /sys/kernel/debug/clock/override.emc/state
            ;;
        *)
            echo $EMC_MAX_FREQ > /sys/kernel/debug/clock/override.emc/rate
            echo 1 > /sys/kernel/debug/clock/override.emc/state
            ;;
    esac
    }

    check_uptime()
    {

    if [ -e "/proc/uptime" ]; then
        uptime=`cat /proc/uptime | cut -d '.' -f1`

    if [ $((uptime)) -lt 90 ]; then
        printf "Error: Please run the script after $((90 - uptime)) Seconds, \
    \notherwise ubuntu init script may override the clock settings!\n"
        exit -1
    fi
    else
        printf "Warning: Could not check system uptime. Please make sure that you run the script 90 Seconds after       bootup, \
    \notherwise ubuntu init script may override the clock settings!\n"
    fi
    }

    main ()
    {
    check_uptime
    while [ -n "$1" ]; do
        case "$1" in
            --show)
                ACTION=show
                ;;
            --store)
                [ -n "$2" ] && CONF_FILE=$2
                ACTION=store
                shift 1
                ;;
            --restore)
                [ -n "$2" ] && CONF_FILE=$2
                ACTION=restore
                shift 1
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            *)
                usage "Unknown option: $1"
                exit 1
                ;;
        esac
        shift 1
    done

    [ `whoami` != root ] && echo Error: Run this script\($0\) as a root user && exit 1

    case $ACTION in
        store)
            if [ -e "${CONF_FILE}" ]; then
                echo "File $CONF_FILE already exists. Can I overwrite it? Y/N:"
                read answer
                case $answer in
                    y|Y)
                        rm -f $CONF_FILE
                        ;;
                    *)
                        echo "Error: file $CONF_FILE already exists!"
                        exit 1
                        ;;
                esac
            fi
            ;;
        restore)
            if [ ! -e "${CONF_FILE}" ]; then
                echo "Error: $CONF_FILE file not found !"
                exit 1
            fi
            restore
            exit 0
            ;;
    esac

    do_cpu
    do_hotplug
    do_clusterswitch
    do_gpu
    do_emc
    do_fan
    }

    main $@
    exit 0
    安装Caffe

    安装Caffe脚本
    $ ./installCaffe.sh
    installCaffe.sh脚本内容为：
    #!/bin/sh
    # Script for installing Caffe support on Jetson TX1 Development Kitls
    # 9-15-16 JetsonHacks.com
    # MIT License
    # Install and compile Caffe on NVIDIA Jetson TX1 Development Kit
    # Prerequisites (which can be installed with JetPack 2):
    # L4T 24.2 (Ubuntu 16.04)
    # OpenCV4Tegra
    # CUDA 8.0
    # cuDNN v5.1
    # Tested with last Github Caffe commit: 80f44100e19fd371ff55beb3ec2ad5919fb6ac43
    sudo add-apt-repository universe
    sudo apt-get update -y
    /bin/echo -e "\e[1;32mLoading Caffe Dependencies.\e[0m"
    sudo apt-get install cmake -y
    # General Dependencies
    sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev \
    libhdf5-serial-dev protobuf-compiler -y
    sudo apt-get install --no-install-recommends libboost-all-dev -y
    # BLAS
    sudo apt-get install libatlas-base-dev -y
    # Remaining Dependencies
    sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev -y
    sudo apt-get install python-dev python-numpy -y

    sudo usermod -a -G video $USER
    /bin/echo -e "\e[1;32mCloning Caffe into the home directory\e[0m"
    # Place caffe in the home directory
    cd $HOME
    # Git clone Caffe
    git clone https://github.com/BVLC/caffe.git 
    cd caffe 
    cp Makefile.config.example Makefile.config
    # Regen the makefile; On 16.04, aarch64 has issues with a static cuda runtime
    cmake -DCUDA_USE_STATIC_CUDA_RUNTIME=OFF
    # Include the hdf5 directory for the includes; 16.04 has issues for some reason
    echo "INCLUDE_DIRS += /usr/include/hdf5/serial/" >> Makefile.config
    /bin/echo -e "\e[1;32mCompiling Caffe\e[0m"
    make -j4 all
    # Run the tests to make sure everything works
    /bin/echo -e "\e[1;32mRunning Caffe Tests\e[0m"
    make -j4 test
    make -j4 runtest
    # The following is a quick timing test ...
    # tools/caffe time --model=models/bvlc_alexnet/deploy.prototxt --gpu=0 
    安装Caffe带有CUDNN支持

    安装installCaffeCuDNN.sh
    $ ./installCaffeCuDNN.sh
    installCaffeCuDNN.sh脚本内容为：
    #!/bin/sh
    # Script for installing Caffe with cuDNN support on Jetson TX1 Development Kitls
    # 9-15-16 JetsonHacks.com
    # MIT License
    # Install and compile Caffe on NVIDIA Jetson TX1 Development Kit
    # Prerequisites (which can be installed with JetPack 2):
    # L4T 24.2 (Ubuntu 16.04)
    # OpenCV4Tegra
    # CUDA 8.0
    # cuDNN v5.1
    # Tested with last Github Caffe commit: 80f44100e19fd371ff55beb3ec2ad5919fb6ac43
    sudo add-apt-repository universe
    sudo apt-get update -y
    /bin/echo -e "\e[1;32mLoading Caffe Dependencies.\e[0m"
    sudo apt-get install cmake -y
    # General Dependencies
    sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev \
    libhdf5-serial-dev protobuf-compiler -y
    sudo apt-get install --no-install-recommends libboost-all-dev -y
    # BLAS
    sudo apt-get install libatlas-base-dev -y
    # Remaining Dependencies
    sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev -y
    sudo apt-get install python-dev python-numpy -y

    sudo usermod -a -G video $USER
    /bin/echo -e "\e[1;32mCloning Caffe into the home directory\e[0m"
    # Place caffe in the home directory
    cd $HOME
    # Git clone Caffe
    git clone https://github.com/BVLC/caffe.git 
    cd caffe 
    cp Makefile.config.example Makefile.config
    # Enable cuDNN usage
    sed -i 's/# USE_CUDNN/USE_CUDNN/g' Makefile.config
    # Regen the makefile; On 16.04, aarch64 has issues with a static cuda runtime
    cmake -DCUDA_USE_STATIC_CUDA_RUNTIME=OFF
    # Include the hdf5 directory for the includes; 16.04 has issues for some reason
    echo "INCLUDE_DIRS += /usr/include/hdf5/serial/" >> Makefile.config
    /bin/echo -e "\e[1;32mCompiling Caffe\e[0m"
    make -j4 all
    # Run the tests to make sure everything works
    /bin/echo -e "\e[1;32mRunning Caffe Tests\e[0m"
    make -j4 test
    make -j4 runtest
    # The following is a quick timing test ...  
    #tools/caffe time --model=models/bvlc_alexnet/deploy.prototxt --gpu=0
    测试：

    Jetson TK1 vs. Jetson TX1 Caffe GPU Example Comparison
    10 iterations, times in milliseconds
    Machine	Average FWD	Average BACK	Average FWD-BACK
    Jetson TK1 (32-bit OS)	234	243	478
    Jetson TX1 (32-bit OS)	179	144	324
    Jetson TX1
    with cuDNN support (32-bit OS)	103	117	224
    Jetson TX1 (64-bit OS)	110	122	233
    Jetson TX1
    with cuDNN support (64-bit)	80	119	200
    安装nvcaffe:

    参考building-nvcaffe
    问题：

    问题1：可能会在runtest卡住

    解决：在下载的安装脚本中make -j4 runtest前增加make -j4 test ，在caffe目录下make clean再执行安装命令
    
    问题2：caffe目录下，没有build目录

    解决：进入caffe目录执行：

    cd ~/caffe
    mkdir build
    cd build
    cmake ..
    cd ..


# TX1安装Qt
    说明：

    介绍如何在TX1上安装Qt
    步骤：

    下载qt：
    地址：安装包qt-everywhere-opensource-src-5.5.1(http://download.qt.io/official_releases/qt/5.5/5.5.1/single/qt-everywhere-opensource-src-5.5.1.tar.gz)
    解压后,修改文件qtbase/mkspecs/linux-arm-gnueabi-g++/qmake.conf
    修改如下：
    #
    # qmake configuration for building with arm-linux-gnueabi-g++
    #

    MAKEFILE_GENERATOR      = UNIX  
    CONFIG                 += incremental  
    QMAKE_INCREMENTAL_STYLE = sublib

    QMAKE_CFLAGS_RELEASE   += -O2 -march=armv7-a  
    QMAKE_CXXFLAGS_RELEASE += -O2 -march=armv7-a

    include(../common/linux.conf)  
    include(../common/gcc-base-unix.conf)  
    include(../common/g++-unix.conf)

    # modifications to g++.conf
    QMAKE_CC                = gcc  
    QMAKE_CXX               = g++  
    QMAKE_LINK              = g++  
    QMAKE_LINK_SHLIB        = g++

    # modifications to linux.conf
    QMAKE_AR                = ar cqs  
    QMAKE_OBJCOPY           = objcopy  
    QMAKE_NM                = nm -P  
    QMAKE_STRIP             = strip  
    load(qt_config)  
    修改qt.pro,去掉文件最后部分的一些不想编译的模块,比如:
    addModule(qtbase)  
    addModule(qtandroidextras, qtbase)  
    addModule(qtmacextras, qtbase)  
    addModule(qtx11extras, qtbase)  
    addModule(qtsvg, qtbase)  
    addModule(qtxmlpatterns, qtbase)  
    addModule(qtdeclarative, qtbase, qtsvg qtxmlpatterns)  
    addModule(qtquickcontrols, qtdeclarative, qtgraphicaleffects)  
    addModule(qtmultimedia, qtbase, qtdeclarative)  
    addModule(qtwinextras, qtbase, qtdeclarative qtmultimedia)  
    addModule(qtactiveqt, qtbase)  
    addModule(qtsystems, qtbase, qtdeclarative)  
    addModule(qtlocation, qtbase, qtdeclarative qtquickcontrols qtsystems)  
    addModule(qtsensors, qtbase, qtdeclarative)  
    #addModule(qtconnectivity, qtbase $$ANDROID_EXTRAS, qtdeclarative)
    addModule(qtfeedback, qtdeclarative, qtmultimedia)  
    addModule(qtpim, qtdeclarative)  
    addModule(qtwebsockets, qtbase, qtdeclarative)  
    addModule(qtwebchannel, qtbase, qtdeclarative qtwebsockets)  
    addModule(qtwebkit, qtbase, qtdeclarative qtlocation qtmultimedia qtsensors qtwebchannel qtxmlpatterns, WebKit.pro)  
    addModule(qttools, qtbase, qtdeclarative qtactiveqt qtwebkit)  
    addModule(qtwebkit-examples, qtwebkit qttools)  
    addModule(qtimageformats, qtbase)  
    #addModule(qt3d, qtdeclarative qtimageformats)
    #addModule(qtcanvas3d, qtdeclarative)
    addModule(qtgraphicaleffects, qtdeclarative)  
    addModule(qtscript, qtbase, qttools)  
    addModule(qtquick1, qtscript, qtsvg qtxmlpatterns qtwebkit)  
    addModule(qtdocgallery, qtdeclarative)  
    #addModule(qtwayland, qtbase, qtdeclarative)
    addModule(qtserialport, qtbase)  
    addModule(qtenginio, qtdeclarative)  
    addModule(qtwebengine, qtquickcontrols qtwebchannel, qtwebkit qtlocation)  
    addModule(qttranslations, qttools)  
    addModule(qtdoc, qtdeclarative)  
    addModule(qtqa, qtbase)  
    到这里,qt里面需要修改的就完成了,但还需要对系统环境做些处理,让其满足qt的编译.
    修改.bashrc,添加:
    export SYSROOT  
    export PKG_CONFIG_SYSROOT_DIR=/  
    export PKG_CONFIG_LIBDIR=$SYSROOT/usr/lib/arm-linux-gnueabihf/pkgconfig:$SYSROOT/usr/share/pkgconfig:$SYSROOT/usr/lib/pkgconfig  
    export PKG_CONFIG_PATH=$SYSROOT/usr/lib/arm-linux-gnueabihf/pkgconfig:$SYSROOT/usr/share/pkgconfig:$SYSROOT/usr/lib/pkgconfig  
    执行source ~/.bashrc让其生效.
    执行下面的命令，安装对xcb的依赖:
    sudo apt-get install libxcb1 libxcb1-dev libx11-xcb1 libx11-xcb-dev libxcb-keysyms1 libxcb-keysyms1-dev libxcb-image0 libxcb-image0-dev libxcb-shm0 libxcb-shm0-dev libxcb-icccm4 libxcb-icccm4-dev libxcb-sync1 libxcb-sync-dev libxcb-xfixes0-dev libxrender-dev libxcb-shape0-dev libxcb-randr0-dev libxcb-render-util0 libxcb-render-util0-dev libxcb-glx0-dev 
    开始编译qt：
    ubuntu@tegra-ubuntu:~/qt-everywhere-opensource-src-5.5.1$ mkdir build  
    ubuntu@tegra-ubuntu:~/qt-everywhere-opensource-src-5.5.1$ cd build/  
    ubuntu@tegra-ubuntu:~/qt-everywhere-opensource-src-5.5.1/build$ ls  
    ubuntu@tegra-ubuntu:~/qt-everywhere-opensource-src-5.5.1/build$ sudo mkdir /opt/qt; ../configure -verbose -release -opensource -xplatform linux-arm-gnueabi-g++ -prefix /opt/qt -no-c++11 -qt-zlib -qt-xcb  
    [sudo] password for ubuntu: 
    + cd qtbase
    + /home/ubuntu/qt-everywhere-opensource-src-5.5.1/qtbase/configure -top-level -verbose -release -opensource -   xplatform linux-arm-gnueabi-g++ -prefix /opt/qt -no-c++11 -qt-zlib -qt-xcb

    This is the Qt Open Source Edition.

    You are licensed to use this software under the terms of  
    the Lesser GNU General Public License (LGPL) versions 2.1.  
    You are also licensed to use this software under the terms of  
    the GNU Lesser General Public License (LGPL) versions 3.

    Type '3' to view the GNU Lesser General Public License version 3.  
    Type 'L' to view the Lesser GNU General Public License version 2.1.  
    Type 'yes' to accept this license offer.  
    Type 'no' to decline this license offer.

    Do you accept the terms of either license? yes  
    继续编译：
    nmake -j4
    sudo make install
    最后在~/.bashrc添加:
    export PATH=/opt/qt/bin:$PATH  
    export LD_LIBRARY_PATH=/opt/qt/lib:$LD_LIBRARY_PATH  
    更新环境：
    source ~/.bashrc
    检查是否成功：
    qmake -version
    
    
# TX1安装ROS kinetic
    说明:

    介绍如何在TX1安装ROS kinetic
    步骤：

    下载安装脚本：
    $ git clone https://github.com/jetsonhacks/installROSTX1.git
    $ cd installROSTX1
    $ vim installROS.sh
    脚本内容如下：
    #!/bin/bash
    # Install Robot Operating System (ROS) on NVIDIA Jetson TX1
    # Maintainer of ARM builds for ROS is http://answers.ros.org/users/1034/ahendrix/
    # Information from:
    # http://wiki.ros.org/kinetic/Installation/UbuntuARM

    # Setup Locale
    # sudo update-locale LANG=C LANGUAGE=C LC_ALL=C LC_MESSAGES=POSIX
    # Setup sources.lst
    sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
    # Setup keys
    sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 0xB01FA116
    # Installation
    sudo apt-get update
    sudo apt-get install ros-kinetic-ros-base -y
    # Add Individual Packages here
    # You can install a specific ROS package (replace underscores with dashes of the package name):
    # sudo apt-get install ros-kinetic-PACKAGE
    # e.g.
    # sudo apt-get install ros-kinetic-navigation
    #
    # To find available packages:
    # apt-cache search ros-kinetic  
    # 
    # Initialize rosdep
    sudo apt-get install python-rosdep -y
    # ssl certificates can get messed up on TX1 for some reason
    sudo c_rehash /etc/ssl/certs
    # Initialize rosdep
    sudo rosdep init
    # To find available packages, use:
    rosdep update
    # Environment Setup
    echo "source /opt/ros/kinetic/setup.bash" >> ~/.bashrc
    source ~/.bashrc
    # Install rosinstall
    sudo apt-get install python-rosinstall -y
    安装的是ros-kinetic-ros-base，更改为：ros-kinetic-desktop-full

    执行安装

    $ ./installROS.sh
    安装结束，则完成ROS的kinetic版本
    检查是否成功,运行：
    roscore
    
# TX1安装Turtlebot
    说明：

    介绍如何在TX1上安装Turtlebot
    Kinetic版本没有完全合适的二进制包，进入二进制安装会有一些包无法安装的，这里采用源码方式安装。
    turtlebot源码安装

    安装准备
    安装好kinetic，参考教程

    安装依赖和更新：

    $ sudo apt-get install python-rosdep python-wstool  
    $ sudo rosdep init
    $ rosdep update
    分别建立三个工作空间rocon，kobuki，turtlebot，下载和编译源码
    建立rocon目录，下载和编译，rocon都有对应的kinetic版本
    $ mkdir ~/rocon
    $ cd ~/rocon
    $ wstool init -j5 src https://raw.github.com/robotics-in-concert/rocon/release/kinetic/rocon.rosinstall
    $ source /opt/ros/kinetic/setup.bash
    $ rosdep install --from-paths src -i -y
    $ catkin_make
    如果wstool更新失败，可以重新更新：
    $ wstool update -t src
    建立kobuki目录，下载和编译.
    kobuki使用kinetic的版本下载会失败，先用indigo版本生成下载的rosinstall文件，再修改对应包为kinetic版本
    $ mkdir ~/kobuki
    $ cd ~/kobuki
    $ wget https://raw.github.com/yujinrobot/yujin_tools/master/rosinstalls/indigo/kobuki.rosinstall 
    $ vim kobuki.rosinstall #参照kobuki.rosinstall文件内容，修改后在进行。
    $ wstool init src -j5 kobuki.rosinstall 
    $ source ~/rocon/devel/setup.bash
    $ rosdep install --from-paths src -i -y
    $ catkin_make   
    kobuki.rosinstall 文件为：
    # THIS IS AN AUTOGENERATED FILE, LAST GENERATED USING wstool ON 2016-12-08
    - git:
    local-name: kobuki
    uri: https://github.com/yujinrobot/kobuki.git
    version: kinetic
    - git:
    local-name: kobuki_core
    uri: https://github.com/yujinrobot/kobuki_core.git
    version: kinetic
    - git:
    local-name: kobuki_desktop
    uri: https://github.com/yujinrobot/kobuki_desktop.git
    version: kinetic
    - git:
    local-name: kobuki_msgs
    uri: https://github.com/yujinrobot/kobuki_msgs.git
    version: kinetic    
    - git:
    local-name: yocs_msgs
    uri: https://github.com/yujinrobot/yocs_msgs.git
    version: release/0.6-kinetic
    - git:
    local-name: yujin_ocs
    uri: https://github.com/yujinrobot/yujin_ocs.git
    version: kinetic
    建立turtlebot目录，下载和编译.
    turtlebot使用kinetic的版本下载会失败，先用indigo版本生成下载的rosinstall文件，再修改对应包为kinetic版本，没有kinetic版本的保持为indigo版本
    $ mkdir ~/turtlebot
    $ cd ~/turtlebot
    $ wget https://raw.github.com/yujinrobot/yujin_tools/master/rosinstalls/indigo/turtlebot.rosinstall
    $ vim turtlebot.rosinstall #参照turtlebot.rosinstall文件内容，修改后在进行。
    $ wstool init src -j5 turtlebot.rosinstall
    $ source ~/kobuki/devel/setup.bash
    $ rosdep install --from-paths src -i -y
    $ catkin_make
    turtlebot.rosinstall文件内容:
    # THIS IS AN AUTOGENERATED FILE, LAST GENERATED USING wstool ON 2016-12-08
    - git:
    local-name: turtlebot
    uri: https://github.com/turtlebot/turtlebot.git
    version: kinetic
    - git:
    local-name: turtlebot_apps
    uri: https://github.com/turtlebot/turtlebot_apps.git
    version: indigo
    - git:
    local-name: turtlebot_create
    uri: https://github.com/turtlebot/turtlebot_create.git
    version: indigo
    - git:
    local-name: turtlebot_create_desktop
    uri: https://github.com/turtlebot/turtlebot_create_desktop.git
    version: kinetic
    - git:
    local-name: turtlebot_interactions
    uri: https://github.com/turtlebot/turtlebot_interactions.git
    version: indigo
    - git:
    local-name: turtlebot_msgs
    uri: https://github.com/turtlebot/turtlebot_msgs.git
    version: indigo
    - git:
    local-name: turtlebot_simulator
    uri: https://github.com/turtlebot/turtlebot_simulator.git
    version: indigo
    
    
    Turtlebot二进制安装：

    执行安装：
    sudo apt-get install ros-kinetic-turtlebot ros-kinetic-turtlebot-apps ros-kinetic-turtlebot-interactions  ros-kinetic-kobuki-ftdi  ros-kinetic-ar-track-alvar-msgs ros-kinetic-rocon-remocon ros-kinetic-rocon-qt-library ros-kinetic-turtlebot-simulator
    有些包可能不能安装 ，如可能为：
     ros-kinetic-rocon-remocon ros-kinetic-rocon-qt-library ros-kinetic-turtlebot-simulator
    上述包采用源安装

    新建工作空间

    mkdir -p ~/turtlebot_ws/src
    cd ~/turtlebot_ws/src
    git clone https://github.com/robotics-in-concert/rocon_qt_gui.git
    git clone https://github.com/turtlebot/turtlebot_simulator.git 
    cd ..
    catkin_make 
    问题：提示pyrcc5，pyrcc4没找到

    解决：安装pyqt4-dev-tools pyqt5-dev-tools

    顺利完成之后，Turtlebot就成功安装

    添加到~/.bashrc:

    source ~/turtlebot_ws/devel/setup.bash
    生成kobuki别名

    $ rosrun kobuki_ftdi create_udev_rules
    安装kinect驱动

    $ sudo apt-get install ros-kinetic-openni-* ros-kinetic-openni2-* ros-kinetic-freenect-*
# TX1编译内核
    说明:
    
    介绍如何在TX1上编译内核
    对于一些雷达、Arduino设备使用USB或ACM,可以通过编译内核增加支持
    步骤：

    新建立目录，下载脚本：
    $ mkdir ~/kernel
    $ cd ~/kernel
    $ git clone https://github.com/jetsonhacks/buildJetsonTX1Kernel.git
    $ cd buildJetsonTX1Kernel
    下载源码并解压到/usr/src/kernel.
    $ ./getKernelSources.sh
    源安装之后，会弹出配置内核窗口， stock kernel 是用-tegra作为local version标识，编辑后保存
    针对ttyUSB支持参数：
    USB support
    - USB CP210x 
    - USB FTDI  
    针对ACM支持参数：

    USB support

    USB Modem (CDC ACM) support
    CONFIG_USB_ACM
    为源打补丁，更容易编译：

    $ ./patchAndBuildKernel.sh
    上面命令复制一些32位的文件，构建内核和模块，模块位于/lib/modules/
    复制最新构建的镜像和zImage文件到/boot目录
    $ ./copyImage.sh
    重启后，新内核即可生效。
    
    
# TX1实现扩展swap交换区大小
    说明：

    介绍如何扩展TX1的swap交换区大小
    实验是在使用SD card作为启动分区，需要同时增加交换分区
    步骤：

    创建脚本:
    mkdir ~/swap/
    cd ~/swap/
    vim createSwapFile.sh
    脚本内容如下：
    #!/bin/bash
    #NVIDIA Jetson TX1 in 3D card
    #Create a swapfile for Ubuntu at the current directory location
    fallocate -l 4G swapfile
    #List out the file
    ls -lh swapfile
    # Change permissions so that only root can use it
    chmod 600 swapfile
    #List out the file
    ls -lh swapfile
    #Set up the Linux swap area
    mkswap swapfile
    #Now start using the swapfile
    swapon swapfile
    #Show that it's now being used
    swapon -s
    设置权限：
    chmod +x createSwapFile.sh
    执行：
    sudo ./createSwapFile.sh
    创建swap为4G大小swap文件。
    设置开机生效：
    $ sudo vim /etc/fstab
    内容如下:
    /home/ubuntu/swap/swapfile none swap sw 0 0
    
# TX1安装TensorFlow(1.0.1)
    说明：

    介绍如何在TX1上安装TensorFlow 1.0.1版本，1.0版本以上可以支持更多功能实现。
    准备：

    利用Jetpack安装如下：
    L4T 24.2.1 an Ubuntu 16.04 64-bit variant (aarch64)
    CUDA 8.0
    cuDNN 5.1.5
    TensorFlow安装需要用到CUDA和cuDNN
    TensorFlow占用比较多空间，TX1通常空间不足，最好增加64G+的U盘作为root分区启动，增加交换分区大小为8G+
    安装：

    安装Java：
    sudo add-apt-repository ppa:webupd8team/java
    sudo apt-get update
    sudo apt-get install oracle-java8-installer
    安装依赖，(使用Python 2.7)
    sudo apt-get install zip unzip autoconf automake libtool curl zlib1g-dev maven -y
    sudo apt-get install python-numpy swig python-dev python-pip python-wheel -y
    安装Bazel(0.5.0版本)
    下载 bazel-0.4.5-dist.zip
    wget https://github.com/bazelbuild/bazel/releases/download/0.4.5/bazel-0.4.5-dist.zip
    解压，进入
    cd bazel-0.4.5-dist
    修改：
    vim src/main/java/com/google/devtools/build/lib/util/CPU.java
    其中28行：ARM("arm", ImmutableSet.of("arm","armv7l"))
    修改为：ARM("arm", ImmutableSet.of("aarch64", "arm","armv7l"))
    编译：
    ./compile.sh
    复制到系统bin目录：
    sudo cp output/bazel /usr/local/bin
    创建swap文件

    创建8G swap文件：
    fallocate -l 8G swapfile
    修改权限
    chmod 600 swapfile
    创建swap区
    mkswap swapfile
    激活
    swapon swapfile
    确认
    swapon -s
    安装TensorFlow

    克隆
    git clone https://github.com/tensorflow/tensorflow.git
    checkout 新版本
    cd tensorflow
    git checkout v1.0.1
    修改：tensorflow/stream_executor/cuda/cuda_gpu_executor.cc
    找到：static int TryToReadNumaNode(conststring &pci_bus_id,intdevice_ordinal)
    添加：#if defined(__APPLE__)
    #ifdef __aarch64__
    LOG(INFO) << "ARM64 does not support NUMA - returning NUMA node zero";
    return 0;
    #elif defined(__APPLE__)
    增加头文件
    sudo cp /usr/include/cudnn.h /usr/lib/aarch64-linux-gnu/include/cudnn.h
    编译：
    ./configure
    配置：
    ubuntu@tegra-ubuntu:~/tensorflow$ ./configure 
    Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7
    Please specify optimization flags to use during compilation [Default is -march=native]: 
    Do you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] y
    jemalloc enabled on Linux
    Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
    No Google Cloud Platform support will be enabled for TensorFlow
    Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
    No Hadoop File System support will be enabled for TensorFlow
    Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y
    XLA JIT support will be enabled for TensorFlow
    Found possible Python library paths:
    /usr/local/lib/python2.7/dist-packages
    /usr/lib/python2.7/dist-packages
    Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

    Using python library path: /usr/local/lib/python2.7/dist-packages
    Do you wish to build TensorFlow with OpenCL support? [y/N] n
    No OpenCL support will be enabled for TensorFlow
    Do you wish to build TensorFlow with CUDA support? [y/N] y
    CUDA support will be enabled for TensorFlow
    Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
    Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 
    Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is  /usr/local/cuda]: 
    Please specify the Cudnn version you want to use. [Leave empty to use system default]: 
    Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
    Please specify a list of comma-separated Cuda compute capabilities you want to build with.
    You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
    Please note that each additional compute capability significantly increases your build time and binary size.
    Extracting Bazel installation...
    .......................
    INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
    .......................
    INFO: All external dependencies fetched successfully.
    Configuration finished
    bazel 编译：
    bazel build -c opt --local_resources 3072,4.0,1.0 --verbose_failures --config=cuda  //tensorflow/tools/pip_package:build_pip_package
    bazel生成whl文件
    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
    保存whl文件
    mv /tmp/tensorflow_pkg/tensorflow-1.0.1-cp27-cp27mu-linux_aarch64.whl $HOME/
    安装
    sudo pip install $HOME/tensorflow-1.0.1-cp27-cp27mu-linux_aarch64.whl
    重启
    sudo reboot
    测试：
    ubuntu@tegra-ubuntu:~$ python
    Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
    [GCC 5.4.0 20160609] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import tensorflow as tf
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
    >>> x = tf.constant(1.0)
    >>> y = tf.constant(2.0)
    >>> z = x + y
    >>> with tf.Session() as sess:
    ...     print z.eval()
    ... 
    I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:874] ARM has no NUMA node, hardcoding to return zero
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
    name: GP10B
    major: 6 minor: 2 memoryClockRate (GHz) 1.3005
    pciBusID 0000:00:00.0
    Total memory: 7.67GiB
    Free memory: 6.79GiB
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GP10B, pci bus id: 0000:00:00.0)
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 6.45G (6929413888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 5.81G (6236472320 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 5.23G (5612825088 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.70G (5051542528 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.23G (4546387968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 3.81G (4091749120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
    I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
    I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices
    I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
    I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
    I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
    I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices
    I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:
    I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2
    3.0
    
    问题：

    错误：
    tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
    解决：
    https://github.com/tensorflow/tensorflow/issues/2559
    https://github.com/tensorflow/tensorflow/issues/2556
    修改：tensorflow/stream_executor/cuda/cuda_blas.cc, 在
    #if CUDA_VERSION >= 7050
    #define EIGEN_HAS_CUDA_FP16
    #endif
    增加定义：
    #if CUDA_VERSION >= 8000
    #define CUBLAS_DATA_HALF CUDA_R_16F
    #endif
